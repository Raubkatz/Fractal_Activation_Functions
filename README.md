# ğŸ§© Fractal-Activation Playground
A fully-reproducible sandbox accompanying  
**â€œFractals in Neural Networks: Introducing a New Class of Activation Functions.â€**

The repo answers three questions:

1. **Do fractal activations help on real tabular benchmarks?** â†’ `01_run_experiments.py`  
2. **How stable / accurate are they across 40 random splits?** â†’ `02_evaluate_results.py`  
3. **Why do they possess higher *expressivity* than ReLU/Tanh?** â†’ `03_expressivity_experiment_enhanced.py`  
4. **What do the raw curves look like?** â†’ `04_plot_activation_functions.py`  

---

## ğŸ’¾ Repository layout

fractal-activation-playground/
â”œâ”€â”€ fractal_activation_functions.py # all 12 custom Ïƒ(Â·)

â”‚

â”œâ”€â”€ 01_run_experiments.py # ğŸš‚ grid-search: 10 data sets Ã— 5 optims Ã— 12 activations

â”œâ”€â”€ 02_evaluate_results.py # ğŸ“Š merge JSON logs â†’ mean / std / min / max tables

â”œâ”€â”€ 03_expressivity_experiment_enhanced.py

â”‚ # ğŸ” replicates Poole-16 / Raghu-17 trajectory analysis

â”œâ”€â”€ 04_plot_activation_functions.py # ğŸ¨ pretty plots of every activation on [-2,2]

â”‚

â”œâ”€â”€ requirements.txt # â€œpip install -r â€¦â€ yields TF + SciPy stack

â””â”€â”€ README.md # you are here
